{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -converting pdf to text\n",
    "# -text to kg(emtities, relationship, embeddings)\n",
    "# -retrival()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!pip install --upgrade pymilvus\n",
    "# !pip install git+https://github.com/zc277584121/graphrag.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '9101287fb67e484b9970dd8d7e31aa05' # Your OpenAI API key\n",
    "llm_model = \"gpt-4o\"  # Or gpt-4-turbo-preview\n",
    "embedding_model = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    read_indexer_covariates,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_relationships,\n",
    "    read_indexer_reports,\n",
    "    read_indexer_text_units,\n",
    ")\n",
    "from graphrag.query.input.loaders.dfs import (\n",
    "    store_entity_semantic_embeddings,\n",
    ")\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.embedding import OpenAIEmbedding\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.question_gen.local_gen import LocalQuestionGen\n",
    "from graphrag.query.structured_search.local_search.mixed_context import (\n",
    "    LocalSearchMixedContext,\n",
    ")\n",
    "from graphrag.query.structured_search.local_search.search import LocalSearch\n",
    "from graphrag.vector_stores.lancedb import LanceDBVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\\20241019-145519\\artifacts\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "  \n",
    "def get_latest_timestamp_dir(base_dir):  \n",
    "    # List all directories in the base directory  \n",
    "    all_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]  \n",
    "      \n",
    "    # Sort the directories based on their names assuming they are timestamped  \n",
    "    all_dirs.sort(reverse=True)  \n",
    "      \n",
    "    # Return the latest directory  \n",
    "    return all_dirs[0] if all_dirs else None  \n",
    "  \n",
    "# Example usage  \n",
    "OUTPUT_DIR = r\"output\"  \n",
    "latest_timestamp = get_latest_timestamp_dir(OUTPUT_DIR)  \n",
    "  \n",
    "if latest_timestamp:  \n",
    "    INPUT_DIR = os.path.join(OUTPUT_DIR, latest_timestamp, \"artifacts\")  \n",
    "    print(INPUT_DIR)  \n",
    "else:  \n",
    "    print(\"No directories found.\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = INPUT_DIR\n",
    "# diesl-graph\\classical_graphrag\\output\\20241019-143614\n",
    "# diesl-graph\\classical_graphrag\\output\\20241019-120138\n",
    "# diesl-graph\\classical_graphrag\\output\\20241019-120138\n",
    "# diesl-graph\\classical_graphrag\\output\\20241019-114417\n",
    "# diesl-graph\\classical_graphrag\\output\\20241014-023025\n",
    "# diesl-graph\\classical_graphrag\\output\\20241014-022450\n",
    "# diesl-graph\\classical_graphrag\\output\\20241014-021151\n",
    "# diesl-graph\\classical_graphrag\\output\\20241014-011736\n",
    "LANCEDB_URI = f\"{INPUT_DIR}/lancedb\"\n",
    "# diesl-graph\\classical_graphrag\\output\\20241013-131846\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "RELATIONSHIP_TABLE = \"create_final_relationships\"\n",
    "COVARIATE_TABLE = \"create_final_covariates\"\n",
    "TEXT_UNIT_TABLE = \"create_final_text_units\"\n",
    "COMMUNITY_LEVEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os  \n",
    "  \n",
    "# # Get the current working directory  \n",
    "# current_path = os.getcwd()  \n",
    "# print(\"Current Path:\", current_path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity count: 207\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>source_id</th>\n",
       "      <th>degree</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>id</th>\n",
       "      <th>size</th>\n",
       "      <th>graph_embedding</th>\n",
       "      <th>community</th>\n",
       "      <th>top_level_node_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DEW CONSTRUCTION</td>\n",
       "      <td>COMPANY, ORGANIZATION</td>\n",
       "      <td>A construction company located at 277 Blair Pa...</td>\n",
       "      <td>57fe050b01845cd18779ab7650252c67</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>b45241d70f0e43fca764df95b2b81f77</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>b45241d70f0e43fca764df95b2b81f77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>CHARLOTTE CENTRAL SCHOOL</td>\n",
       "      <td>PROJECT, LOCATION</td>\n",
       "      <td>A school located at 408 Hinesburg Road, Charlo...</td>\n",
       "      <td>57fe050b01845cd18779ab7650252c67</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4119fd06010c494caa07f439b333f4c5</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4119fd06010c494caa07f439b333f4c5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>GYPSUM WALL BOARD</td>\n",
       "      <td>MATERIAL, PRODUCT</td>\n",
       "      <td>A construction material used in wall and ceili...</td>\n",
       "      <td>57fe050b01845cd18779ab7650252c67</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d3835bf3dda84ead99deadbeac5d0d7d</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>d3835bf3dda84ead99deadbeac5d0d7d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>BECKY ST. GEORGE</td>\n",
       "      <td>PERSON, ROLE</td>\n",
       "      <td>Submittal Manager at DEW Construction, respons...</td>\n",
       "      <td>57fe050b01845cd18779ab7650252c67</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>077d2820ae1845bcbb1803379a3d1eae</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>077d2820ae1845bcbb1803379a3d1eae</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>STEEL ELEMENTS INTERNATIONAL</td>\n",
       "      <td>COMPANY, CONTRACTOR</td>\n",
       "      <td>The contractor responsible for the submittal, ...</td>\n",
       "      <td>57fe050b01845cd18779ab7650252c67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3671ea0dd4e84c1a9b02c5ab2c8f4bac</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3671ea0dd4e84c1a9b02c5ab2c8f4bac</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level                         title                   type  \\\n",
       "0      0              DEW CONSTRUCTION  COMPANY, ORGANIZATION   \n",
       "1      0      CHARLOTTE CENTRAL SCHOOL      PROJECT, LOCATION   \n",
       "2      0             GYPSUM WALL BOARD      MATERIAL, PRODUCT   \n",
       "3      0              BECKY ST. GEORGE           PERSON, ROLE   \n",
       "4      0  STEEL ELEMENTS INTERNATIONAL    COMPANY, CONTRACTOR   \n",
       "\n",
       "                                         description  \\\n",
       "0  A construction company located at 277 Blair Pa...   \n",
       "1  A school located at 408 Hinesburg Road, Charlo...   \n",
       "2  A construction material used in wall and ceili...   \n",
       "3  Submittal Manager at DEW Construction, respons...   \n",
       "4  The contractor responsible for the submittal, ...   \n",
       "\n",
       "                          source_id  degree  human_readable_id  \\\n",
       "0  57fe050b01845cd18779ab7650252c67       4                  0   \n",
       "1  57fe050b01845cd18779ab7650252c67       2                  1   \n",
       "2  57fe050b01845cd18779ab7650252c67       1                  2   \n",
       "3  57fe050b01845cd18779ab7650252c67       1                  3   \n",
       "4  57fe050b01845cd18779ab7650252c67       1                  4   \n",
       "\n",
       "                                 id  size graph_embedding community  \\\n",
       "0  b45241d70f0e43fca764df95b2b81f77     4            None      None   \n",
       "1  4119fd06010c494caa07f439b333f4c5     2            None      None   \n",
       "2  d3835bf3dda84ead99deadbeac5d0d7d     1            None         4   \n",
       "3  077d2820ae1845bcbb1803379a3d1eae     1            None      None   \n",
       "4  3671ea0dd4e84c1a9b02c5ab2c8f4bac     1            None      None   \n",
       "\n",
       "                  top_level_node_id  x  y  \n",
       "0  b45241d70f0e43fca764df95b2b81f77  0  0  \n",
       "1  4119fd06010c494caa07f439b333f4c5  0  0  \n",
       "2  d3835bf3dda84ead99deadbeac5d0d7d  0  0  \n",
       "3  077d2820ae1845bcbb1803379a3d1eae  0  0  \n",
       "4  3671ea0dd4e84c1a9b02c5ab2c8f4bac  0  0  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read nodes table to get community and degree data\n",
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "entity_embedding_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "\n",
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
    "\n",
    "# load description embeddings to an in-memory lancedb vectorstore\n",
    "# to connect to a remote db, specify url and port values.\n",
    "description_embedding_store = LanceDBVectorStore(\n",
    "    collection_name=\"entity_description_embeddings\",\n",
    ")\n",
    "description_embedding_store.connect(db_uri=LANCEDB_URI)\n",
    "entity_description_embeddings = store_entity_semantic_embeddings(\n",
    "    entities=entities, vectorstore=description_embedding_store\n",
    ")\n",
    "\n",
    "print(f\"Entity count: {len(entity_df)}\")\n",
    "entity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship count: 83\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "      <th>description</th>\n",
       "      <th>text_unit_ids</th>\n",
       "      <th>id</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>source_degree</th>\n",
       "      <th>target_degree</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEW CONSTRUCTION</td>\n",
       "      <td>CHARLOTTE CENTRAL SCHOOL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DEW Construction is managing the renovation pr...</td>\n",
       "      <td>[57fe050b01845cd18779ab7650252c67]</td>\n",
       "      <td>babe97e1d9784cffa1c85abc1e588126</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEW CONSTRUCTION</td>\n",
       "      <td>BECKY ST. GEORGE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Becky St. George is the Submittal Manager at D...</td>\n",
       "      <td>[57fe050b01845cd18779ab7650252c67]</td>\n",
       "      <td>1033a18c45aa4584b2aef6ab96890351</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEW CONSTRUCTION</td>\n",
       "      <td>MIKE WANDERLICH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mike Wanderlich is involved in the submittal r...</td>\n",
       "      <td>[57fe050b01845cd18779ab7650252c67]</td>\n",
       "      <td>c9b8ce91fc2945b4907fe35519339cac</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEW CONSTRUCTION</td>\n",
       "      <td>LUKE KEENAN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Luke Keenan is a reviewer at DEW Construction</td>\n",
       "      <td>[57fe050b01845cd18779ab7650252c67]</td>\n",
       "      <td>fa3c4204421c48609e52c8de2da4c654</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHARLOTTE CENTRAL SCHOOL</td>\n",
       "      <td>STEEL ELEMENTS INTERNATIONAL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Steel Elements International is the contractor...</td>\n",
       "      <td>[57fe050b01845cd18779ab7650252c67]</td>\n",
       "      <td>53af055f068244d0ac861b2e89376495</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     source                        target  weight  \\\n",
       "0          DEW CONSTRUCTION      CHARLOTTE CENTRAL SCHOOL     1.0   \n",
       "1          DEW CONSTRUCTION              BECKY ST. GEORGE     1.0   \n",
       "2          DEW CONSTRUCTION               MIKE WANDERLICH     1.0   \n",
       "3          DEW CONSTRUCTION                   LUKE KEENAN     1.0   \n",
       "4  CHARLOTTE CENTRAL SCHOOL  STEEL ELEMENTS INTERNATIONAL     1.0   \n",
       "\n",
       "                                         description  \\\n",
       "0  DEW Construction is managing the renovation pr...   \n",
       "1  Becky St. George is the Submittal Manager at D...   \n",
       "2  Mike Wanderlich is involved in the submittal r...   \n",
       "3      Luke Keenan is a reviewer at DEW Construction   \n",
       "4  Steel Elements International is the contractor...   \n",
       "\n",
       "                        text_unit_ids                                id  \\\n",
       "0  [57fe050b01845cd18779ab7650252c67]  babe97e1d9784cffa1c85abc1e588126   \n",
       "1  [57fe050b01845cd18779ab7650252c67]  1033a18c45aa4584b2aef6ab96890351   \n",
       "2  [57fe050b01845cd18779ab7650252c67]  c9b8ce91fc2945b4907fe35519339cac   \n",
       "3  [57fe050b01845cd18779ab7650252c67]  fa3c4204421c48609e52c8de2da4c654   \n",
       "4  [57fe050b01845cd18779ab7650252c67]  53af055f068244d0ac861b2e89376495   \n",
       "\n",
       "  human_readable_id  source_degree  target_degree  rank  \n",
       "0                 0              4              2     6  \n",
       "1                 1              4              1     5  \n",
       "2                 2              4              1     5  \n",
       "3                 3              4              1     5  \n",
       "4                 4              2              1     3  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship_df = pd.read_parquet(f\"{INPUT_DIR}/{RELATIONSHIP_TABLE}.parquet\")\n",
    "relationships = read_indexer_relationships(relationship_df)\n",
    "\n",
    "print(f\"Relationship count: {len(relationship_df)}\")\n",
    "relationship_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: covariates are turned off by default, because they generally need prompt tuning to be valuable\n",
    "# # Please see the GRAPHRAG_CLAIM_* settings\n",
    "# covariate_df = pd.read_parquet(f\"{INPUT_DIR}/{COVARIATE_TABLE}.parquet\")\n",
    "\n",
    "# claims = read_indexer_covariates(covariate_df)\n",
    "\n",
    "# print(f\"Claim records: {len(claims)}\")\n",
    "# covariates = {\"claims\": claims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '9101287fb67e484b9970dd8d7e31aa05' # Your OpenAI API key\n",
    "llm_model = \"gpt-4o\"  # Or gpt-4-turbo-preview\n",
    "embedding_model = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report records: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community</th>\n",
       "      <th>full_content</th>\n",
       "      <th>level</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>rank_explanation</th>\n",
       "      <th>summary</th>\n",
       "      <th>findings</th>\n",
       "      <th>full_content_json</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td># Gypsum Board and Associated Standards\\n\\nThe...</td>\n",
       "      <td>2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Gypsum Board and Associated Standards</td>\n",
       "      <td>The impact severity rating is high due to the ...</td>\n",
       "      <td>The community centers around Gypsum Board, a k...</td>\n",
       "      <td>[{'explanation': 'Gypsum Board is a versatile ...</td>\n",
       "      <td>{\\n    \"title\": \"Gypsum Board and Associated S...</td>\n",
       "      <td>175cefb9-42b1-431d-b9b3-016db7671eac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td># Gold Bond Building Products and National Gyp...</td>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Gold Bond Building Products and National Gypsu...</td>\n",
       "      <td>The impact severity rating is moderate to high...</td>\n",
       "      <td>The community is centered around Gold Bond Bui...</td>\n",
       "      <td>[{'explanation': 'Gold Bond Building Products,...</td>\n",
       "      <td>{\\n    \"title\": \"Gold Bond Building Products a...</td>\n",
       "      <td>a7f5cd2f-be33-4a62-aa50-b18df76fc2eb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td># Georgia-Pacific Gypsum and ToughRock Firegua...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Georgia-Pacific Gypsum and ToughRock Fireguard...</td>\n",
       "      <td>The impact severity rating is high due to the ...</td>\n",
       "      <td>The community centers around Georgia-Pacific G...</td>\n",
       "      <td>[{'explanation': 'Georgia-Pacific Gypsum is a ...</td>\n",
       "      <td>{\\n    \"title\": \"Georgia-Pacific Gypsum and To...</td>\n",
       "      <td>f212b414-d7a2-4df0-9654-a1b287186069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td># Georgia-Pacific Gypsum LLC and ToughRock Fir...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Georgia-Pacific Gypsum LLC and ToughRock Fireg...</td>\n",
       "      <td>The impact severity rating is moderate due to ...</td>\n",
       "      <td>The community centers around Georgia-Pacific G...</td>\n",
       "      <td>[{'explanation': 'Georgia-Pacific Gypsum LLC i...</td>\n",
       "      <td>{\\n    \"title\": \"Georgia-Pacific Gypsum LLC an...</td>\n",
       "      <td>5a074a44-1122-418f-a77c-2ac15b375b19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td># GRIDMARX and XP Hi-Abuse Gypsum Board Commun...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>GRIDMARX and XP Hi-Abuse Gypsum Board Community</td>\n",
       "      <td>The impact severity rating is high due to the ...</td>\n",
       "      <td>This community centers around GRIDMARX and XP ...</td>\n",
       "      <td>[{'explanation': 'GRIDMARX is a preprinted fas...</td>\n",
       "      <td>{\\n    \"title\": \"GRIDMARX and XP Hi-Abuse Gyps...</td>\n",
       "      <td>2406900d-ad99-4533-8c0d-32d595cf074f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  community                                       full_content  level  rank  \\\n",
       "0        14  # Gypsum Board and Associated Standards\\n\\nThe...      2   7.5   \n",
       "1        15  # Gold Bond Building Products and National Gyp...      2   6.5   \n",
       "2        10  # Georgia-Pacific Gypsum and ToughRock Firegua...      1   7.5   \n",
       "3        11  # Georgia-Pacific Gypsum LLC and ToughRock Fir...      1   6.5   \n",
       "4        12  # GRIDMARX and XP Hi-Abuse Gypsum Board Commun...      1   7.5   \n",
       "\n",
       "                                               title  \\\n",
       "0              Gypsum Board and Associated Standards   \n",
       "1  Gold Bond Building Products and National Gypsu...   \n",
       "2  Georgia-Pacific Gypsum and ToughRock Fireguard...   \n",
       "3  Georgia-Pacific Gypsum LLC and ToughRock Fireg...   \n",
       "4    GRIDMARX and XP Hi-Abuse Gypsum Board Community   \n",
       "\n",
       "                                    rank_explanation  \\\n",
       "0  The impact severity rating is high due to the ...   \n",
       "1  The impact severity rating is moderate to high...   \n",
       "2  The impact severity rating is high due to the ...   \n",
       "3  The impact severity rating is moderate due to ...   \n",
       "4  The impact severity rating is high due to the ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The community centers around Gypsum Board, a k...   \n",
       "1  The community is centered around Gold Bond Bui...   \n",
       "2  The community centers around Georgia-Pacific G...   \n",
       "3  The community centers around Georgia-Pacific G...   \n",
       "4  This community centers around GRIDMARX and XP ...   \n",
       "\n",
       "                                            findings  \\\n",
       "0  [{'explanation': 'Gypsum Board is a versatile ...   \n",
       "1  [{'explanation': 'Gold Bond Building Products,...   \n",
       "2  [{'explanation': 'Georgia-Pacific Gypsum is a ...   \n",
       "3  [{'explanation': 'Georgia-Pacific Gypsum LLC i...   \n",
       "4  [{'explanation': 'GRIDMARX is a preprinted fas...   \n",
       "\n",
       "                                   full_content_json  \\\n",
       "0  {\\n    \"title\": \"Gypsum Board and Associated S...   \n",
       "1  {\\n    \"title\": \"Gold Bond Building Products a...   \n",
       "2  {\\n    \"title\": \"Georgia-Pacific Gypsum and To...   \n",
       "3  {\\n    \"title\": \"Georgia-Pacific Gypsum LLC an...   \n",
       "4  {\\n    \"title\": \"GRIDMARX and XP Hi-Abuse Gyps...   \n",
       "\n",
       "                                     id  \n",
       "0  175cefb9-42b1-431d-b9b3-016db7671eac  \n",
       "1  a7f5cd2f-be33-4a62-aa50-b18df76fc2eb  \n",
       "2  f212b414-d7a2-4df0-9654-a1b287186069  \n",
       "3  5a074a44-1122-418f-a77c-2ac15b375b19  \n",
       "4  2406900d-ad99-4533-8c0d-32d595cf074f  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)\n",
    "\n",
    "print(f\"Report records: {len(report_df)}\")\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text unit records: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>document_ids</th>\n",
       "      <th>entity_ids</th>\n",
       "      <th>relationship_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57fe050b01845cd18779ab7650252c67</td>\n",
       "      <td>---- Page 1 ----\\nDEW\\nCONSTRUCTION\\nDEW Const...</td>\n",
       "      <td>1500</td>\n",
       "      <td>[ca5cbf4db4c8e3ba35a4547210722d5a]</td>\n",
       "      <td>[b45241d70f0e43fca764df95b2b81f77, 4119fd06010...</td>\n",
       "      <td>[babe97e1d9784cffa1c85abc1e588126, 1033a18c45a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>488f6c425b2a94e2ec6634bd28490f37</td>\n",
       "      <td>Advantages\\n· Specially designed gypsum core w...</td>\n",
       "      <td>1500</td>\n",
       "      <td>[ca5cbf4db4c8e3ba35a4547210722d5a]</td>\n",
       "      <td>[1fd3fa8bb5a2408790042ab9573779ee, 27f9fbe6ad8...</td>\n",
       "      <td>[fc01e9baa80e417c9206f941bb279407, 56d0e5ebe79...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>490a4f510b4c01e1699c0cd209b10744</td>\n",
       "      <td>� 5/8\" (16 mm)\\nNail Pull Resistance1\\n≥ 87 lb...</td>\n",
       "      <td>1500</td>\n",
       "      <td>[ca5cbf4db4c8e3ba35a4547210722d5a]</td>\n",
       "      <td>[1fd3fa8bb5a2408790042ab9573779ee, 27f9fbe6ad8...</td>\n",
       "      <td>[fc01e9baa80e417c9206f941bb279407, 0adb2d9941f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08457fe8eb8bcba5634aa44b157d25c2</td>\n",
       "      <td>up on the field\\nnails. The total quantity of...</td>\n",
       "      <td>1500</td>\n",
       "      <td>[ca5cbf4db4c8e3ba35a4547210722d5a]</td>\n",
       "      <td>[1fd3fa8bb5a2408790042ab9573779ee, 27f9fbe6ad8...</td>\n",
       "      <td>[fc01e9baa80e417c9206f941bb279407, 0adb2d9941f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6eb55ef89dc98e83dabfce0347f7ae69</td>\n",
       "      <td>a vapor\\nretarder in exterior ceilings behind...</td>\n",
       "      <td>1500</td>\n",
       "      <td>[ca5cbf4db4c8e3ba35a4547210722d5a]</td>\n",
       "      <td>[1fd3fa8bb5a2408790042ab9573779ee, 27f9fbe6ad8...</td>\n",
       "      <td>[fc01e9baa80e417c9206f941bb279407, 7c49f2710e8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  57fe050b01845cd18779ab7650252c67   \n",
       "1  488f6c425b2a94e2ec6634bd28490f37   \n",
       "2  490a4f510b4c01e1699c0cd209b10744   \n",
       "3  08457fe8eb8bcba5634aa44b157d25c2   \n",
       "4  6eb55ef89dc98e83dabfce0347f7ae69   \n",
       "\n",
       "                                                text  n_tokens  \\\n",
       "0  ---- Page 1 ----\\nDEW\\nCONSTRUCTION\\nDEW Const...      1500   \n",
       "1  Advantages\\n· Specially designed gypsum core w...      1500   \n",
       "2  � 5/8\" (16 mm)\\nNail Pull Resistance1\\n≥ 87 lb...      1500   \n",
       "3   up on the field\\nnails. The total quantity of...      1500   \n",
       "4   a vapor\\nretarder in exterior ceilings behind...      1500   \n",
       "\n",
       "                         document_ids  \\\n",
       "0  [ca5cbf4db4c8e3ba35a4547210722d5a]   \n",
       "1  [ca5cbf4db4c8e3ba35a4547210722d5a]   \n",
       "2  [ca5cbf4db4c8e3ba35a4547210722d5a]   \n",
       "3  [ca5cbf4db4c8e3ba35a4547210722d5a]   \n",
       "4  [ca5cbf4db4c8e3ba35a4547210722d5a]   \n",
       "\n",
       "                                          entity_ids  \\\n",
       "0  [b45241d70f0e43fca764df95b2b81f77, 4119fd06010...   \n",
       "1  [1fd3fa8bb5a2408790042ab9573779ee, 27f9fbe6ad8...   \n",
       "2  [1fd3fa8bb5a2408790042ab9573779ee, 27f9fbe6ad8...   \n",
       "3  [1fd3fa8bb5a2408790042ab9573779ee, 27f9fbe6ad8...   \n",
       "4  [1fd3fa8bb5a2408790042ab9573779ee, 27f9fbe6ad8...   \n",
       "\n",
       "                                    relationship_ids  \n",
       "0  [babe97e1d9784cffa1c85abc1e588126, 1033a18c45a...  \n",
       "1  [fc01e9baa80e417c9206f941bb279407, 56d0e5ebe79...  \n",
       "2  [fc01e9baa80e417c9206f941bb279407, 0adb2d9941f...  \n",
       "3  [fc01e9baa80e417c9206f941bb279407, 0adb2d9941f...  \n",
       "4  [fc01e9baa80e417c9206f941bb279407, 7c49f2710e8...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_unit_df = pd.read_parquet(f\"{INPUT_DIR}/{TEXT_UNIT_TABLE}.parquet\")\n",
    "text_units = read_indexer_text_units(text_unit_df)\n",
    "\n",
    "print(f\"Text unit records: {len(text_unit_df)}\")\n",
    "text_unit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"9101287fb67e484b9970dd8d7e31aa05\"\n",
    "# llm_model = os.environ[\"GRAPHRAG_LLM_MODEL\"]\n",
    "# embedding_model = os.environ[\"GRAPHRAG_EMBEDDING_MODEL\"]\n",
    "api_base=\"https://diesl-eus-openai-dev.openai.azure.com/\"\n",
    "api_version=\"2024-02-15-preview\"\n",
    "api_key = '9101287fb67e484b9970dd8d7e31aa05' # Your OpenAI API key\n",
    "llm_model = \"gpt-4o\"  # Or gpt-4-turbo-preview\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_base=api_base,\n",
    "    api_version=api_version,\n",
    "    model=llm_model,\n",
    "    api_type=OpenaiApiType.AzureOpenAI,  # OpenaiApiType.OpenAI or OpenaiApiType.AzureOpenAI\n",
    "    max_retries=4,\n",
    ")\n",
    "\n",
    "token_encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "text_embedder = OpenAIEmbedding(\n",
    "    api_key=api_key,\n",
    "    api_base=api_base,\n",
    "    api_version=api_version,\n",
    "    api_type=OpenaiApiType.AzureOpenAI,\n",
    "    model=embedding_model,\n",
    "    deployment_name=embedding_model,\n",
    "    max_retries=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder = LocalSearchMixedContext(\n",
    "    community_reports=reports,\n",
    "    text_units=text_units,\n",
    "    entities=entities,\n",
    "    relationships=relationships,\n",
    "    # if you did not run covariates during indexing, set this to None\n",
    "\n",
    "    entity_text_embeddings=description_embedding_store,\n",
    "    embedding_vectorstore_key=EntityVectorStoreKey.ID,  # if the vectorstore uses entity title as ids, set this to EntityVectorStoreKey.TITLE\n",
    "    text_embedder=text_embedder,\n",
    "    token_encoder=token_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_unit_prop: proportion of context window dedicated to related text units\n",
    "# community_prop: proportion of context window dedicated to community reports.\n",
    "# The remaining proportion is dedicated to entities and relationships. Sum of text_unit_prop and community_prop should be <= 1\n",
    "# conversation_history_max_turns: maximum number of turns to include in the conversation history.\n",
    "# conversation_history_user_turns_only: if True, only include user queries in the conversation history.\n",
    "# top_k_mapped_entities: number of related entities to retrieve from the entity description embedding store.\n",
    "# top_k_relationships: control the number of out-of-network relationships to pull into the context window.\n",
    "# include_entity_rank: if True, include the entity rank in the entity table in the context window. Default entity rank = node degree.\n",
    "# include_relationship_weight: if True, include the relationship weight in the context window.\n",
    "# include_community_rank: if True, include the community rank in the context window.\n",
    "# return_candidate_context: if True, return a set of dataframes containing all candidate entity/relationship/covariate records that\n",
    "# could be relevant. Note that not all of these records will be included in the context window. The \"in_context\" column in these\n",
    "# dataframes indicates whether the record is included in the context window.\n",
    "# max_tokens: maximum number of tokens to use for the context window.\n",
    "\n",
    "\n",
    "local_context_params = {\n",
    "    \"text_unit_prop\": 0.5,\n",
    "    \"community_prop\": 0.1,\n",
    "    \"conversation_history_max_turns\": 5,\n",
    "    \"conversation_history_user_turns_only\": True,\n",
    "    \"top_k_mapped_entities\": 10,\n",
    "    \"top_k_relationships\": 10,\n",
    "    \"include_entity_rank\": True,\n",
    "    \"include_relationship_weight\": True,\n",
    "    \"include_community_rank\": False,\n",
    "    \"return_candidate_context\": False,\n",
    "    \"embedding_vectorstore_key\": EntityVectorStoreKey.ID,  # set this to EntityVectorStoreKey.TITLE if the vectorstore uses entity title as ids\n",
    "    \"max_tokens\": 12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "}\n",
    "\n",
    "llm_params = {\n",
    "    \"max_tokens\": 2_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 1000=1500)\n",
    "    \"temperature\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = LocalSearch(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    llm_params=llm_params,\n",
    "    context_builder_params=local_context_params,\n",
    "    response_type=\"multiple paragraphs\",  # free form text describing the response type and format, can be anything, e.g. prioritized list, single paragraph, multiple paragraphs, multiple-page report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have access to the specific \"Section Includes\" portion of the document you're referring to. If you can provide that section or more details, I can help analyze the information based on the data available.\n"
     ]
    }
   ],
   "source": [
    "result = await search_engine.asearch(\"\"\"\n",
    "Step 1: Leverage the 'Section Includes' portion of the document to identify the key product(s) within the text document.\n",
    "Step 2: Identify the aliases used to refer to the key products outlined within the 'Section Includes' portion of the PDF.\n",
    "\ta) Example aliases include 'GYPBD-1, RF-1'. Return only a numbered list of products that have an alias.\n",
    "Step 3: Using the list of products and aliases you created in step 2, verify  no product or alias is excluded from our list. If you identify a new product and alias, add this new product to the existing list. \n",
    "\n",
    "\n",
    "\"\"\")\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1612\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[0;32m   1611\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1612\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_models.py:763\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[1;32m--> 763\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://diesl-eus-openai-dev.openai.azure.com//openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124mwhat is the document about  \u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m search_engine\u001b[38;5;241m.\u001b[39masearch(question)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mresponse)\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\search.py:82\u001b[0m, in \u001b[0;36mLocalSearch.asearch\u001b[1;34m(self, query, conversation_history, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     search_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msystem_prompt\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     75\u001b[0m         context_data\u001b[38;5;241m=\u001b[39mcontext_text, response_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_type\n\u001b[0;32m     76\u001b[0m     )\n\u001b[0;32m     77\u001b[0m     search_messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     78\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: search_prompt},\n\u001b[0;32m     79\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: query},\n\u001b[0;32m     80\u001b[0m     ]\n\u001b[1;32m---> 82\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39magenerate(\n\u001b[0;32m     83\u001b[0m         messages\u001b[38;5;241m=\u001b[39msearch_messages,\n\u001b[0;32m     84\u001b[0m         streaming\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     85\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_params,\n\u001b[0;32m     87\u001b[0m     )\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SearchResult(\n\u001b[0;32m     90\u001b[0m         response\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[0;32m     91\u001b[0m         context_data\u001b[38;5;241m=\u001b[39mcontext_records,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m         prompt_tokens\u001b[38;5;241m=\u001b[39mnum_tokens(search_prompt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_encoder),\n\u001b[0;32m     96\u001b[0m     )\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\query\\llm\\oai\\chat_openai.py:110\u001b[0m, in \u001b[0;36mChatOpenAI.agenerate\u001b[1;34m(self, messages, streaming, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     retryer \u001b[38;5;241m=\u001b[39m AsyncRetrying(\n\u001b[0;32m    105\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop_after_attempt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries),\n\u001b[0;32m    106\u001b[0m         wait\u001b[38;5;241m=\u001b[39mwait_exponential_jitter(\u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m    107\u001b[0m         reraise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    108\u001b[0m         retry\u001b[38;5;241m=\u001b[39mretry_if_exception_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_types),  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     )\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m retryer:\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m attempt:\n\u001b[0;32m    112\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(\n\u001b[0;32m    113\u001b[0m                 messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m    114\u001b[0m                 streaming\u001b[38;5;241m=\u001b[39mstreaming,\n\u001b[0;32m    115\u001b[0m                 callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    116\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    117\u001b[0m             )\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:166\u001b[0m, in \u001b[0;36mAsyncRetrying.__anext__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__anext__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AttemptManager:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m         do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_state)\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m do \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:153\u001b[0m, in \u001b[0;36mAsyncRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    151\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\_utils.py:99\u001b[0m, in \u001b[0;36mwrap_to_async_func.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[1;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\query\\llm\\oai\\chat_openai.py:112\u001b[0m, in \u001b[0;36mChatOpenAI.agenerate\u001b[1;34m(self, messages, streaming, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m retryer:\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m attempt:\n\u001b[1;32m--> 112\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(\n\u001b[0;32m    113\u001b[0m                 messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m    114\u001b[0m                 streaming\u001b[38;5;241m=\u001b[39mstreaming,\n\u001b[0;32m    115\u001b[0m                 callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    116\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    117\u001b[0m             )\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reporter\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError at agenerate(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\graphrag\\query\\llm\\oai\\chat_openai.py:176\u001b[0m, in \u001b[0;36mChatOpenAI._agenerate\u001b[1;34m(self, messages, streaming, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model:\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_MODEL_REQUIRED_MSG)\n\u001b[1;32m--> 176\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    177\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    178\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    179\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstreaming,\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    181\u001b[0m )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n\u001b[0;32m    183\u001b[0m     full_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:1490\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1453\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m   1454\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1488\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m AsyncStream[ChatCompletionChunk]:\n\u001b[0;32m   1489\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m-> 1490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[0;32m   1493\u001b[0m             {\n\u001b[0;32m   1494\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m   1495\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m   1496\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   1497\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m   1498\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m   1499\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m   1500\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m   1501\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m   1502\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m   1503\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m   1504\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m   1505\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m   1506\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m   1507\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m   1508\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m   1509\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m   1510\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m   1511\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m   1512\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m   1513\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m   1514\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m   1515\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m   1516\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m   1517\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m   1518\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m   1519\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m   1520\u001b[0m             },\n\u001b[0;32m   1521\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m   1522\u001b[0m         ),\n\u001b[0;32m   1523\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   1524\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m   1525\u001b[0m         ),\n\u001b[0;32m   1526\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m   1527\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1528\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[0;32m   1529\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1838\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1824\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1825\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1826\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1833\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1834\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[0;32m   1835\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1836\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1837\u001b[0m     )\n\u001b[1;32m-> 1838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1532\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1533\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1534\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1535\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1536\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1537\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1538\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1618\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[0;32m   1616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maclose()\n\u001b[1;32m-> 1618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1619\u001b[0m         input_options,\n\u001b[0;32m   1620\u001b[0m         cast_to,\n\u001b[0;32m   1621\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1622\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1623\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1624\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1625\u001b[0m     )\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1663\u001b[0m, in \u001b[0;36mAsyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1660\u001b[0m timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_retry_timeout(remaining_retries, options, response_headers)\n\u001b[0;32m   1661\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[1;32m-> 1663\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m   1665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1666\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1667\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1670\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1671\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_core\\_eventloop.py:87\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(delay)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msleep\u001b[39m(delay: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    Pause the current task for the specified duration.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    :param delay: the duration, in seconds\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m get_async_backend()\u001b[38;5;241m.\u001b[39msleep(delay)\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py:2292\u001b[0m, in \u001b[0;36mAsyncIOBackend.sleep\u001b[1;34m(cls, delay)\u001b[0m\n\u001b[0;32m   2290\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   2291\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msleep\u001b[39m(\u001b[38;5;28mcls\u001b[39m, delay: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2292\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(delay)\n",
      "File \u001b[1;32mc:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:665\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(delay, result)\u001b[0m\n\u001b[0;32m    661\u001b[0m h \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mcall_later(delay,\n\u001b[0;32m    662\u001b[0m                     futures\u001b[38;5;241m.\u001b[39m_set_result_unless_cancelled,\n\u001b[0;32m    663\u001b[0m                     future, result)\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     h\u001b[38;5;241m.\u001b[39mcancel()\n",
      "\u001b[1;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "what is the document about  \n",
    "\"\"\"\n",
    "result = await search_engine.asearch(question)\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2098973318.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[78], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    a) Example aliases include 'GYPBD-1, RF-1'\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "!python -m graphrag.query --root . --method local \"\"\"\n",
    "\n",
    "Step 1: Leverage the 'Section Includes' portion of the document to identify the key product(s) within the PDF.  \n",
    "Step 2: Identify the aliases used to refer to the key products outlined within the 'Section Includes' portion of the PDF.  \n",
    "  a) Example aliases include 'GYPBD-1, RF-1'  \n",
    "  Return only a numbered list of products that have an alias.  \n",
    "Step 3: Using the list of products and aliases you created in step 2, verify no product or alias is excluded from our list. If you identify a new product and alias, add this new product to the existing list.  \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aziz1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    read_indexer_covariates,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_relationships,\n",
    "    read_indexer_reports,\n",
    "    read_indexer_text_units,\n",
    ")\n",
    "from graphrag.query.input.loaders.dfs import (\n",
    "    store_entity_semantic_embeddings,\n",
    ")\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.embedding import OpenAIEmbedding\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.question_gen.local_gen import LocalQuestionGen\n",
    "from graphrag.query.structured_search.local_search.mixed_context import (\n",
    "    LocalSearchMixedContext,\n",
    ")\n",
    "from graphrag.query.structured_search.local_search.search import LocalSearch\n",
    "from graphrag.vector_stores.lancedb import LanceDBVectorStore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
