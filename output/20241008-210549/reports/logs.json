{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"TYPE X BOARD\"\nDescription List: [\"A type of gypsum board that is UL or WH listed for fire resistance\", \"A type of gypsum board with enhanced fire-resistance properties, UL or WH listed\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"GEORGIA-PACIFIC GYPSUM\"\nDescription List: [\"A company that manufactures construction materials, including DensGlass Sheathing and ToughRock Fireguard C Soffit Board\", \"Manufacturer of DensGlass SheathingManufacturer of ToughRock Span 24 Ceiling Board\", \"Manufacturer of ToughRock Fireguard C Soffit Board and DensGlass Shaftliner\", \"Manufacturer of ToughRock Mold-Guard Board\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"UL\"\nDescription List: [\"\", \"Underwriters Laboratories, a certification body that lists fire-resistant materials\", \"Underwriters Laboratories, an organization that certifies products for safety and performance\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"CERTAINTEED CORPORATION\"\nDescription List: [\"A company that manufactures construction materials, including ProRoc Brand Exterior Soffit Board\", \"Manufacturer of Extreme Impact Resistant Drywall with M2Tech\", \"Manufacturer of ProRoc Brand Exterior Soffit Board\", \"Manufacturer of ProRoc Brand Gypsum Board with M2Tech\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"USG CORPORATION\"\nDescription List: [\"A company that manufactures construction materials, including Sheetrock Brand Sag-Resistant Interior Gypsum Ceiling Board and Securock Glass-Mat Sheathing\", \"Manufacturer of Securock Glass-Mat SheathingManufacturer of Durock Brand Cement BoardManufacturer of Sheetrock Brand Sag-Resistant Interior Gypsum Ceiling Board\", \"Manufacturer of Sheetrock Brand Gypsum Panels\", \"Manufacturer of Sheetrock Brand Mold Tough - VHI Abuse-Resistant panels and Durock Brand Cement Board\", \"Manufacturer of Sheetrock Exterior Gypsum Ceiling Board\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"FIRE RATED SYSTEM\"\nDescription List: [\"A ceiling system installed in accordance with UL design guidelines indicated on drawings and details to achieve fire resistance\", \"System installed in accordance with UL design guidelines indicated on drawings and details\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"SOUND INSULATION\"\nDescription List: [\"Insulation material installed to reduce sound transmission, typically installed prior to gypsum board unless readily installed afterward\", \"Material used to reduce sound transmission, installed prior to gypsum boardMaterial used to reduce sound transmission, installed prior to gypsum board unless readily installed after\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"RECESSED FIXTURES\"\nDescription List: [\"Fixtures installed within the ceiling, adjacent to which cross tees are installed\", \"Fixtures that are installed within the ceiling, requiring adjacent cross tees for support\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"CEILING INSULATION\"\nDescription List: [\"Blanket insulation for sound attenuation, laid in place for continuous wall-to-wall coverage throughout the space to receive such insulation\", \"Blanket insulation installed for sound attenuation, laid in place in the ceiling\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"UL DESIGN GUIDELINES\"\nDescription List: [\"Guidelines provided by UL for the installation of fire rated systems\", \"Guidelines provided by Underwriters Laboratories (UL) for achieving fire resistance in construction\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ASTM C 840\"\nDescription List: [\"Standard Specification for Application and Finishing of Gypsum Board\", \"Standard for the application and finishing of gypsum board\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"STATE BUILDING CODE\"\nDescription List: [\"Code that includes seismic requirements for diagonal hanger wire splay bracing\", \"The building code of the state, which includes seismic requirements and other construction standards\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"STRUCTURE\"\nDescription List: [\"The existing building framework to which various components like the top runner and suspended ceiling system are attached\", \"The overall framework to which hanger wires are tightly wrapped\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"DOUBLE LAYER APPLICATION\"\nDescription List: [\"A method of installing two layers of material, such as gypsum board, on walls and ceilings, with specific fastening and spacing requirements\", \"A type of gypsum board installation for walls and ceilings where both layers are mechanically fastened to supports with screws\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"PARTITION INSULATION\"\nDescription List: [\"Blanket insulation for sound attenuation, completely filling spaces between studs to full height of partition/wall, fitting closely to work that penetrates partition/wall\", \"Blanket insulation installed for sound attenuation, completely filling spaces between studs to the full height of the partition/wall\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"CONDUIT\"\nDescription List: [\"A tube or trough for protecting electric wiring that penetrates gypsum board assemblies\", \"Pipes or tubes through which electrical wires are run, around which sealant is applied\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"DUCTS\"\nDescription List: [\"Channels for air flow, around which sealant is applied\", \"Passages used in heating, ventilation, and air conditioning to deliver and remove air that penetrate gypsum board assemblies\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"PIPE\"\nDescription List: [\"A tube used to convey water, gas, oil, or other fluid substances that penetrates gypsum board assemblies\", \"Cylindrical components for fluid transport, around which sealant is applied\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ROUGH-IN BOXES\"\nDescription List: [\"Boxes for electrical connections, around which sealant is applied\", \"Electrical boxes installed during the rough-in phase of construction that penetrate gypsum board assemblies\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ROUGH OPENINGS\"\nDescription List: [\"Openings left for the installation of other trades, with board joints located to avoid alignment with edges of openings unless control joints are installed\", \"Openings left in gypsum board assemblies for the installation of other trades\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"CERTAINTEED CORPORATION\"\nDescription List: [\"A company that manufactures construction materials, including ProRoc Brand Exterior Soffit Board\", \"Manufacturer of Extreme Impact Resistant Drywall with M2Tech\", \"Manufacturer of ProRoc Brand Exterior Soffit Board\", \"Manufacturer of ProRoc Brand Gypsum Board with M2Tech\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"STRUCTURE\"\nDescription List: [\"The existing building framework to which various components like the top runner and suspended ceiling system are attached\", \"The overall framework to which hanger wires are tightly wrapped\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"DOUBLE LAYER APPLICATION\"\nDescription List: [\"A method of installing two layers of material, such as gypsum board, on walls and ceilings, with specific fastening and spacing requirements\", \"A type of gypsum board installation for walls and ceilings where both layers are mechanically fastened to supports with screws\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"PARTITION INSULATION\"\nDescription List: [\"Blanket insulation for sound attenuation, completely filling spaces between studs to full height of partition/wall, fitting closely to work that penetrates partition/wall\", \"Blanket insulation installed for sound attenuation, completely filling spaces between studs to the full height of the partition/wall\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"FIRE RATED SYSTEM\"\nDescription List: [\"A ceiling system installed in accordance with UL design guidelines indicated on drawings and details to achieve fire resistance\", \"System installed in accordance with UL design guidelines indicated on drawings and details\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ASTM C 840\"\nDescription List: [\"Standard Specification for Application and Finishing of Gypsum Board\", \"Standard for the application and finishing of gypsum board\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"DUCTS\"\nDescription List: [\"Channels for air flow, around which sealant is applied\", \"Passages used in heating, ventilation, and air conditioning to deliver and remove air that penetrate gypsum board assemblies\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"UL DESIGN GUIDELINES\"\nDescription List: [\"Guidelines provided by UL for the installation of fire rated systems\", \"Guidelines provided by Underwriters Laboratories (UL) for achieving fire resistance in construction\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"STATE BUILDING CODE\"\nDescription List: [\"Code that includes seismic requirements for diagonal hanger wire splay bracing\", \"The building code of the state, which includes seismic requirements and other construction standards\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"SOUND INSULATION\"\nDescription List: [\"Insulation material installed to reduce sound transmission, typically installed prior to gypsum board unless readily installed afterward\", \"Material used to reduce sound transmission, installed prior to gypsum boardMaterial used to reduce sound transmission, installed prior to gypsum board unless readily installed after\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"PIPE\"\nDescription List: [\"A tube used to convey water, gas, oil, or other fluid substances that penetrates gypsum board assemblies\", \"Cylindrical components for fluid transport, around which sealant is applied\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"CONDUIT\"\nDescription List: [\"A tube or trough for protecting electric wiring that penetrates gypsum board assemblies\", \"Pipes or tubes through which electrical wires are run, around which sealant is applied\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"CEILING INSULATION\"\nDescription List: [\"Blanket insulation for sound attenuation, laid in place for continuous wall-to-wall coverage throughout the space to receive such insulation\", \"Blanket insulation installed for sound attenuation, laid in place in the ceiling\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"RECESSED FIXTURES\"\nDescription List: [\"Fixtures installed within the ceiling, adjacent to which cross tees are installed\", \"Fixtures that are installed within the ceiling, requiring adjacent cross tees for support\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ROUGH OPENINGS\"\nDescription List: [\"Openings left for the installation of other trades, with board joints located to avoid alignment with edges of openings unless control joints are installed\", \"Openings left in gypsum board assemblies for the installation of other trades\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ROUGH-IN BOXES\"\nDescription List: [\"Boxes for electrical connections, around which sealant is applied\", \"Electrical boxes installed during the rough-in phase of construction that penetrate gypsum board assemblies\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"DUCTS\"\nDescription List: [\"Channels for air flow, around which sealant is applied\", \"Passages used in heating, ventilation, and air conditioning to deliver and remove air that penetrate gypsum board assemblies\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"PARTITION INSULATION\"\nDescription List: [\"Blanket insulation for sound attenuation, completely filling spaces between studs to full height of partition/wall, fitting closely to work that penetrates partition/wall\", \"Blanket insulation installed for sound attenuation, completely filling spaces between studs to the full height of the partition/wall\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ASTM C 840\"\nDescription List: [\"Standard Specification for Application and Finishing of Gypsum Board\", \"Standard for the application and finishing of gypsum board\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"STATE BUILDING CODE\"\nDescription List: [\"Code that includes seismic requirements for diagonal hanger wire splay bracing\", \"The building code of the state, which includes seismic requirements and other construction standards\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"FIRE RATED SYSTEM\"\nDescription List: [\"A ceiling system installed in accordance with UL design guidelines indicated on drawings and details to achieve fire resistance\", \"System installed in accordance with UL design guidelines indicated on drawings and details\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"UL DESIGN GUIDELINES\"\nDescription List: [\"Guidelines provided by UL for the installation of fire rated systems\", \"Guidelines provided by Underwriters Laboratories (UL) for achieving fire resistance in construction\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ROUGH OPENINGS\"\nDescription List: [\"Openings left for the installation of other trades, with board joints located to avoid alignment with edges of openings unless control joints are installed\", \"Openings left in gypsum board assemblies for the installation of other trades\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"CONDUIT\"\nDescription List: [\"A tube or trough for protecting electric wiring that penetrates gypsum board assemblies\", \"Pipes or tubes through which electrical wires are run, around which sealant is applied\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"PIPE\"\nDescription List: [\"A tube used to convey water, gas, oil, or other fluid substances that penetrates gypsum board assemblies\", \"Cylindrical components for fluid transport, around which sealant is applied\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"DOUBLE LAYER APPLICATION\"\nDescription List: [\"A method of installing two layers of material, such as gypsum board, on walls and ceilings, with specific fastening and spacing requirements\", \"A type of gypsum board installation for walls and ceilings where both layers are mechanically fastened to supports with screws\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"RECESSED FIXTURES\"\nDescription List: [\"Fixtures installed within the ceiling, adjacent to which cross tees are installed\", \"Fixtures that are installed within the ceiling, requiring adjacent cross tees for support\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"CEILING INSULATION\"\nDescription List: [\"Blanket insulation for sound attenuation, laid in place for continuous wall-to-wall coverage throughout the space to receive such insulation\", \"Blanket insulation installed for sound attenuation, laid in place in the ceiling\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ROUGH-IN BOXES\"\nDescription List: [\"Boxes for electrical connections, around which sealant is applied\", \"Electrical boxes installed during the rough-in phase of construction that penetrate gypsum board assemblies\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"SOUND INSULATION\"\nDescription List: [\"Insulation material installed to reduce sound transmission, typically installed prior to gypsum board unless readily installed afterward\", \"Material used to reduce sound transmission, installed prior to gypsum boardMaterial used to reduce sound transmission, installed prior to gypsum board unless readily installed after\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"RECESSED FIXTURES\"\nDescription List: [\"Fixtures installed within the ceiling, adjacent to which cross tees are installed\", \"Fixtures that are installed within the ceiling, requiring adjacent cross tees for support\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"CONDUIT\"\nDescription List: [\"A tube or trough for protecting electric wiring that penetrates gypsum board assemblies\", \"Pipes or tubes through which electrical wires are run, around which sealant is applied\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ROUGH OPENINGS\"\nDescription List: [\"Openings left for the installation of other trades, with board joints located to avoid alignment with edges of openings unless control joints are installed\", \"Openings left in gypsum board assemblies for the installation of other trades\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ASTM C 840\"\nDescription List: [\"Standard Specification for Application and Finishing of Gypsum Board\", \"Standard for the application and finishing of gypsum board\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"STATE BUILDING CODE\"\nDescription List: [\"Code that includes seismic requirements for diagonal hanger wire splay bracing\", \"The building code of the state, which includes seismic requirements and other construction standards\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"SOUND INSULATION\"\nDescription List: [\"Insulation material installed to reduce sound transmission, typically installed prior to gypsum board unless readily installed afterward\", \"Material used to reduce sound transmission, installed prior to gypsum boardMaterial used to reduce sound transmission, installed prior to gypsum board unless readily installed after\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"UL DESIGN GUIDELINES\"\nDescription List: [\"Guidelines provided by UL for the installation of fire rated systems\", \"Guidelines provided by Underwriters Laboratories (UL) for achieving fire resistance in construction\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"FIRE RATED SYSTEM\"\nDescription List: [\"A ceiling system installed in accordance with UL design guidelines indicated on drawings and details to achieve fire resistance\", \"System installed in accordance with UL design guidelines indicated on drawings and details\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"DOUBLE LAYER APPLICATION\"\nDescription List: [\"A method of installing two layers of material, such as gypsum board, on walls and ceilings, with specific fastening and spacing requirements\", \"A type of gypsum board installation for walls and ceilings where both layers are mechanically fastened to supports with screws\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ROUGH-IN BOXES\"\nDescription List: [\"Boxes for electrical connections, around which sealant is applied\", \"Electrical boxes installed during the rough-in phase of construction that penetrate gypsum board assemblies\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"PIPE\"\nDescription List: [\"A tube used to convey water, gas, oil, or other fluid substances that penetrates gypsum board assemblies\", \"Cylindrical components for fluid transport, around which sealant is applied\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"CEILING INSULATION\"\nDescription List: [\"Blanket insulation for sound attenuation, laid in place for continuous wall-to-wall coverage throughout the space to receive such insulation\", \"Blanket insulation installed for sound attenuation, laid in place in the ceiling\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"CONDUIT\"\nDescription List: [\"A tube or trough for protecting electric wiring that penetrates gypsum board assemblies\", \"Pipes or tubes through which electrical wires are run, around which sealant is applied\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ASTM C 840\"\nDescription List: [\"Standard Specification for Application and Finishing of Gypsum Board\", \"Standard for the application and finishing of gypsum board\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 86400 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ROUGH OPENINGS\"\nDescription List: [\"Openings left for the installation of other trades, with board joints located to avoid alignment with edges of openings unless control joints are installed\", \"Openings left in gypsum board assemblies for the installation of other trades\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"DOUBLE LAYER APPLICATION\"\nDescription List: [\"A method of installing two layers of material, such as gypsum board, on walls and ceilings, with specific fastening and spacing requirements\", \"A type of gypsum board installation for walls and ceilings where both layers are mechanically fastened to supports with screws\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"SOUND INSULATION\"\nDescription List: [\"Insulation material installed to reduce sound transmission, typically installed prior to gypsum board unless readily installed afterward\", \"Material used to reduce sound transmission, installed prior to gypsum boardMaterial used to reduce sound transmission, installed prior to gypsum board unless readily installed after\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"FIRE RATED SYSTEM\"\nDescription List: [\"A ceiling system installed in accordance with UL design guidelines indicated on drawings and details to achieve fire resistance\", \"System installed in accordance with UL design guidelines indicated on drawings and details\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"ROUGH-IN BOXES\"\nDescription List: [\"Boxes for electrical connections, around which sealant is applied\", \"Electrical boxes installed during the rough-in phase of construction that penetrate gypsum board assemblies\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"UL DESIGN GUIDELINES\"\nDescription List: [\"Guidelines provided by UL for the installation of fire rated systems\", \"Guidelines provided by Underwriters Laboratories (UL) for achieving fire resistance in construction\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"PIPE\"\nDescription List: [\"A tube used to convey water, gas, oil, or other fluid substances that penetrates gypsum board assemblies\", \"Cylindrical components for fluid transport, around which sealant is applied\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"CEILING INSULATION\"\nDescription List: [\"Blanket insulation for sound attenuation, laid in place for continuous wall-to-wall coverage throughout the space to receive such insulation\", \"Blanket insulation installed for sound attenuation, laid in place in the ceiling\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "\nYou are an expert in Construction Specification Analysis. You are skilled at extracting and interpreting detailed requirements from construction documents and specifications. You are adept at helping people identify the relationships and structure within the community of interest, ensuring that all stakeholders understand the intricate details and dependencies in the Construction Specification Requirements Extraction domain.\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, concise description in The primary language of the provided text is \"English.\". Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\n\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\n#######\n-Data-\nEntities: \"STATE BUILDING CODE\"\nDescription List: [\"Code that includes seismic requirements for diagonal hanger wire splay bracing\", \"The building code of the state, which includes seismic requirements and other construction standards\"]\n#######\nOutput:"}}
{"type": "error", "data": "Error executing verb \"summarize_descriptions\" in create_summarized_entities: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\datashaper\\workflow\\workflow.py\", line 415, in _execute_verb\n    result = await result\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 184, in summarize_descriptions\n    await get_resolved_entities(row, semaphore) for row in output.itertuples()\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 147, in get_resolved_entities\n    results = await asyncio.gather(*futures)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 167, in do_summarize_descriptions\n    results = await strategy_exec(\n              ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\strategies\\graph_intelligence\\run_graph_intelligence.py\", line 34, in run\n    return await run_summarize_descriptions(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\strategies\\graph_intelligence\\run_graph_intelligence.py\", line 67, in run_summarize_descriptions\n    result = await extractor(items=items, descriptions=descriptions)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 73, in __call__\n    result = await self._summarize_descriptions(items, descriptions)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 106, in _summarize_descriptions\n    result = await self._summarize_descriptions_with_llm(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 125, in _summarize_descriptions_with_llm\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": null}
{"type": "error", "data": "Error running pipeline!", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\run.py\", line 325, in run_pipeline\n    result = await workflow.run(context, callbacks)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\datashaper\\workflow\\workflow.py\", line 369, in run\n    timing = await self._execute_verb(node, context, callbacks)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\datashaper\\workflow\\workflow.py\", line 415, in _execute_verb\n    result = await result\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 184, in summarize_descriptions\n    await get_resolved_entities(row, semaphore) for row in output.itertuples()\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 147, in get_resolved_entities\n    results = await asyncio.gather(*futures)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 167, in do_summarize_descriptions\n    results = await strategy_exec(\n              ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\strategies\\graph_intelligence\\run_graph_intelligence.py\", line 34, in run\n    return await run_summarize_descriptions(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\strategies\\graph_intelligence\\run_graph_intelligence.py\", line 67, in run_summarize_descriptions\n    result = await extractor(items=items, descriptions=descriptions)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 73, in __call__\n    result = await self._summarize_descriptions(items, descriptions)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 106, in _summarize_descriptions\n    result = await self._summarize_descriptions_with_llm(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 125, in _summarize_descriptions_with_llm\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\aziz1\\Desktop\\Projects\\diesl\\graphrag\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": null}
